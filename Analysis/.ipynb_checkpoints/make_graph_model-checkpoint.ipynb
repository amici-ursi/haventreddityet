{
 "metadata": {
  "name": "",
  "signature": "sha256:16696c852b42a6962b9417f1951722e8dd5f09c4e764767265f3fe80bead07a7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Make graphical model "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This file generates a undirected graph of subreddits with their jaccard similarity. It need the category dicttionary, adjacent dictionary as well as the descriptions dictionary "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import networkx as nx\n",
      "import pickle\n",
      "import math"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "make graph function"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Add a node for each subreddit and an edge between related subreddits"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#make a graphical model of subreddits with an adjacent list. Fill categories and other labels.\n",
      "def make_graph(adj_dict, cat_list_dict, des_dict, skip_list = []):\n",
      "    \n",
      "    G = nx.Graph()\n",
      "    index_dict = dict()\n",
      "    idx = 0\n",
      "    \n",
      "    #make an index for each node    \n",
      "    for node in adj_dict:\n",
      "        #for skipping certain subreddit, e.g. defaults \n",
      "        if node in skip_list:\n",
      "            continue\n",
      "        index_dict[node] = idx\n",
      "        idx += 1\n",
      "    \n",
      "    #Add edges and keep track of the links internally\n",
      "    for node in adj_dict:\n",
      "        if node in skip_list:\n",
      "            continue\n",
      "        links_list = []\n",
      "        for adj_node_weight in adj_dict[node]:\n",
      "            if adj_node_weight[0] in skip_list:\n",
      "                continue\n",
      "            links_list.append((index_dict[adj_node_weight[0]],adj_node_weight[1]))\n",
      "            G.add_edge(index_dict[node], index_dict[adj_node_weight[0]], weight=adj_node_weight[1])\n",
      "            \n",
      "        #sort links so they dispay in order of most similar\n",
      "        links_list = sorted(links_list, key = lambda x: x[1], reverse = True)\n",
      "        \n",
      "        #add nodes and links to graph\n",
      "        cat_vals = [cat[1] for cat in cat_list_dict[node]]\n",
      "        \n",
      "        #find descriptions for subreddits \n",
      "        if node in des_dict:\n",
      "            start_subt = des_dict[node][0].find(':')\n",
      "            if start_subt<0:\n",
      "                subt = des_dict[node][0]\n",
      "            else:\n",
      "                subt = des_dict[node][0][start_subt+1:]\n",
      "            des = des_dict[node][1]\n",
      "            nsub = des_dict[node][2]\n",
      "            age = des_dict[node][3]\n",
      "        else:\n",
      "            subt = ''\n",
      "            des = ''\n",
      "            nsub = ''\n",
      "            age = ''\n",
      "        \n",
      "        #Add the nodes to graph with all of the features stored in that node. \n",
      "        G.add_node(index_dict[node],\\\n",
      "                   subtitle = subt,\\\n",
      "                   description = des,\\\n",
      "                   nsubscribers = nsub,\\\n",
      "                   age = age,\\\n",
      "                   index = index_dict[node],\\\n",
      "                   links = [link[0] for link in links_list],\\\n",
      "                   weights = [link[1] for link in links_list],\\\n",
      "                   cat_names = [cat[0] for cat in cat_list_dict[node]],\\\n",
      "                   cat_values = cat_vals,\\\n",
      "                   cat1 = 'none' if sum(cat_vals) == 0 else sorted(cat_list_dict[node], key = lambda x: x[1], reverse = True)[0][0],\\\n",
      "                   score=float(len(adj_dict[node])),\\\n",
      "                   level= ( 1 if node not in default_subreddits else 2),\\\n",
      "                   weblink =str(\"http://www.reddit.com/r/\"+node),\\\n",
      "                   label=node.lower())\n",
      "    return G"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load required dictionaries"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "default_subreddits = pickle.load(open('../data/default_subs_dict.pkl','rd'))\n",
      "adj_dict = pickle.load(open('../data/adj_dict.pkl','rd'))\n",
      "adj_dict['notthesubreddityourelookingfor'] = []\n",
      "cat_dict = pickle.load(open('../data/cat_sim_dict.pkl','rd'))\n",
      "cat_dict['notthesubreddityourelookingfor'] = []\n",
      "descript_dict = pickle.load(open('../data/description3_dict.pkl','rd'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Run"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "G = make_graph(adj_dict, cat_dict, descript_dict)#, skip_list = default_subreddits)\n",
      "print \"Number of nodes: \", G.number_of_nodes()\n",
      "print \"Number of edges: \", G.number_of_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of nodes:  8641\n",
        "Number of edges:  239320\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Add extra features "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def add_graph_attr(G):\n",
      "    #pr = nx.pagerank(G, alpha = 0.9)\n",
      "    degree = nx.degree(G)\n",
      "    #clustering = nx.clustering(G)\n",
      "    for node in G:\n",
      "        G.node[node]['degree'] = degree[node]\n",
      "        #G.node[node]['clustering'] = clustering[node]\n",
      "        #G.node[node]['pagerank'] = pr[node]\n",
      "    \n",
      "add_graph_attr(G)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "G.node[7498]['weblink'] = 'https://www.youtube.com/watch?v=dQw4w9WgXcQ'\n",
      "G.node[7498]['score'] = 10000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Save"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.dump(G,open('../data/graph.pkl','wd'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    }
   ],
   "metadata": {}
  }
 ]
}